Cell 1 – Import Libraries
This cell imports all the libraries required for spam classification:
pandas → for handling datasets.
train_test_split → to divide data into training and testing sets.
CountVectorizer → converts text data into numeric word-count features (if needed).
KNeighborsClassifier → for KNN model.
SVC → for Support Vector Machine model.
accuracy_score, classification_report → for evaluating performance.


Cell 2 – Read the Dataset
Loads the emails.csv dataset.
Displays dataset shape and first few columns to confirm it’s loaded correctly.
Identifies the target column (used to indicate spam or not spam).


Cell 3 – Clean and Prepare Data
Cleans column names by removing spaces and newline characters.
Drops unnecessary columns like IDs.
Defines X (features) and y (target).
Ensures all features are numeric, filling missing values with 0.
Verifies no string columns remain.


Cell 4 – Split Dataset
Splits the dataset:
80% for training (used to train both models)
20% for testing (used for performance evaluation)
random_state=42 ensures reproducibility.


Cell 5 – Train and Test KNN Model
Creates a KNN model with k = 3 neighbors.
Trains it using the training data.
Predicts email labels (spam/not spam) for the test data.
Displays accuracy and a classification report (precision, recall, f1-score).


Cell 6 – Train and Test SVM Model
Builds a Support Vector Machine (SVM) with a linear kernel.
Trains and tests on the same dataset.
Prints accuracy and detailed classification metrics.


Cell 7 – Compare KNN and SVM Performance
Compares accuracy scores of both models.
Prints which one performs better.
This fulfills the “Analyze their performance” part of the question.



ALGORITHM --
1. Start the program.
2. Import all required libraries.
3. Load the emails.csv dataset.
4. Clean the dataset and remove unnecessary columns.
5. Separate features (X) and target (y).
6. Split the data into training and testing sets (80:20).
7. Train the KNN classifier and evaluate accuracy.
8. Train the SVM classifier and evaluate accuracy.
9. Compare both models’ performances.
10. Display which model performs better.

11. Stop the program.

⭐ K-Nearest Neighbors (KNN) – Theory

K-Nearest Neighbors (KNN) is a supervised machine learning algorithm used for classification and regression.
In classification, it predicts the class of a new data point by looking at the K closest training examples.

✔ How KNN Works:

Choose a value for K (number of neighbors).

Compute the distance between the new data point and all training data.

Select the K nearest neighbors.

Use majority voting among these neighbors to assign a class.

✔ Key Points:

No training phase → lazy learner.

Uses distance measures (Euclidean distance most common).

Works best when data is small and well-scaled.

✔ Advantages:

Simple and easy to understand.

No model assumptions.

✔ Disadvantages:

Slow for large datasets.

Sensitive to irrelevant features and scaling.

Not ideal for high-dimensional text data.

⭐ Support Vector Machine (SVM) – Theory

Support Vector Machine (SVM) is a supervised classification algorithm that finds the best separating boundary (hyperplane) between classes.

SVM tries to maximize the margin, which is the distance between the separating boundary and the nearest data points (support vectors).

✔ How SVM Works:

Maps data into a high-dimensional space.

Finds the optimal hyperplane separating classes.

Maximizes the margin between classes for best separation.

Uses kernel functions (Linear, RBF, Polynomial) to handle complex data.

✔ Advantages:

Works extremely well on high-dimensional data (like text).

High accuracy and good generalization.

Effective even when features are many.

✔ Disadvantages:

Training can be slower on large datasets.

Requires parameter tuning (C, kernel).
